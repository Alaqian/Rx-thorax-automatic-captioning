{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation\n",
    "\n",
    "\n",
    "Applying :class:`sklearn.decomposition.NMF` and\n",
    ":class:`sklearn.decomposition.LatentDirichletAllocation` on the Rx thorax report corpus and extract additive models of the topic structure of the\n",
    "corpus.  The output is a list of topics, each represented as a list of\n",
    "terms (weights are not shown).\n",
    "\n",
    "Non-negative Matrix Factorization is applied with two different objective\n",
    "functions: the Frobenius norm, and the generalized Kullback-Leibler divergence.\n",
    "The latter is equivalent to Probabilistic Latent Semantic Indexing.\n",
    "\n",
    "The time complexity is polynomial in NMF. In LDA, the time complexity is\n",
    "proportional to (n_samples * iterations).\n",
    "\n",
    "Source: http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 0.740s.\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 3.341s.\n",
      "Extracting tf features for LDA...\n",
      "done in 3.086s.\n",
      "\n",
      "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=206369 and n_features=1000...\n",
      "done in 29.054s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: alter sin radiolog significativas signific grand no inspir plac identif hallazgos observ inter fdo rest estudi torax parenquim visualiz parenquimat\n",
      "Topic #1: signific hallazg sin patologico fdo radiolog cardiomediastin entid siluet aspect patolog variacion dorsal escoliosis paciente respect parenquim normales espondilosis visualiz\n",
      "Topic #2: con pleural izquierd derech derram aument relacion probabl densid bilateral atelectasi basal sen hemitorax costofren pinzamient hili valor bas infiltr\n",
      "Topic #3: normal dentr limit siluet cardiomediastin normalidad estudi cardiotorac indic pulmon parenquim alto rang torax exploracion libres posteroanterior preoperatori cardi variant\n",
      "Topic #4: epoc sign radiolog atrap aere sugest marc dorsal import inter cardiomegalia aereo lev significativos prominent vascular apical torax escoliosis derecho\n",
      "Topic #5: condens no ni apreci infiltr pulmonar parenquimat pulmonares observ visualiz identif estudi actual identific entid nodul clar inspir imagen plac\n",
      "Topic #6: significacion radiolog sin hallazg parenquimat observ mejori senil rx preoperatori radiografi control anteroposterior dat torax empeor rang lateral sid aportados\n",
      "Topic #7: enfermed metastas pulmon no evident sign estudi observ mastectomi sug tubercul objetiv secundari mam actual estudio identif axil pulmonar metastasica\n",
      "Topic #8: patolog hallazg inter identif no pacient edad evidenci posteroanterior sin torax radiografi relevancia cardiomediastin foc siluet radiolog senil estudi parenquim\n",
      "Topic #9: extrem ven distal central via con cav sond superior nasogastr yugul catet derech subclavi trav venos tub entrad auricul endotraqueal\n",
      "Topic #10: hallazg sin relev significativos relevantes inter hallazgos rest relevancia torax radiografi posteroanterior interes sospech consolid preoperatori compara lesion aere atrap\n",
      "Topic #11: elongacion parenquim pulmonar dorsal aortic escoliosis grand alteraciones aortica cardiomegali siluet indic cardiomediastin cardiotorac cambi limit cronic alto tronc aort\n",
      "Topic #12: edad pacient acord cambi paciente con compat cronic identif rest habit constitucional no parenquimat remit proyeccion secundari torax realiz degener\n",
      "Topic #13: estudi cambi previ respect fech con sin comp ayer compar 2012 objetiv mejori relacion 2011 11 12 10 rest anterior\n",
      "\n",
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=206369 and n_features=1000...\n",
      "done in 136.517s.\n",
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: sin radiolog alter signific rest hallazgos grand significativas fdo cambios relev alteraciones relevancia interes patologico resen resenables picaz aspect hallazg\n",
      "Topic #1: sin hallazg signific patolog relev significativos relevantes relevancia patologico evidenci torax aspect rx radiografi lobul suci mastectomi pa inspiratori escas\n",
      "Topic #2: con derech relacion izquierd infiltr pleural probabl estudi valor lobul nodul bilateral previ atelectasi pequen engros densid aument superior hemitorax\n",
      "Topic #3: normal dentr limit siluet normalidad cardiomediastin rang variant alto normales acig cardi ict descendente dia desviacion desplaz despeg deslustr desflec\n",
      "Topic #4: sign radiolog epoc atrap sugest aere marc aereo retroesternal import tip lev tram cardiomegalia enfisem ginecomasti aplan hiperinsuflacion bronquiectasi fdo\n",
      "Topic #5: no pulmonar infiltr ni condens apreci observ parenquimat pulmonares visualiz plac identif inspir objetiv identific imagen nodul grand sug actual\n",
      "Topic #6: significacion parenquimat torax radiografi sospech pulmonar caract lesion observ cronico senil protesis consolid mamari anteroposterior cardiomegali simpl posteroanterior rx hallazg\n",
      "Topic #7: pulmon torax no cambi metastas enfermed radiografi cronic parenquim posteroanterior evident estudi preoperatori suci secundari sign column mecan degener mastectomi\n",
      "Topic #8: cambi pacient edad con acord paciente patolog inter hili compat peribroncovascul cronic remit prominent rest identif engros consult orig vascular\n",
      "Topic #9: pleural con derram pulmon valor relacion bilateral patron condensacion aument izquierd predomini derech dat tub densid hemitorax clinic intersticial edem\n",
      "Topic #10: superior via ven extrem central derech yugul subclavi cav catet distal venos trav izquierd auricul marcapas entrad interpretacion infiltr bibasal\n",
      "Topic #11: elongacion dorsal escoliosis pulmonar sen cardiomegali hili indic parenquim prominent pinzamient aortic cardiotorac fractur siluet derech aortica costofren vascular costal\n",
      "Topic #12: con sond nasogastr tub extrem distal endotraqueal pulmonar cambi infradiafragmat traqueostomi canul parenquim situacion infradiafragmatico cm grand traqueostomia infradiafragmatica marcapas\n",
      "Topic #13: previ estudi respect cambi fech comp mejori significativos objetiv compar control ayer rest 2012 lev 2011 2009 2010 anterior 2013\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=206369 and n_features=1000...\n",
      "iteration: 1 of max_iter: 5\n",
      "iteration: 2 of max_iter: 5\n",
      "iteration: 3 of max_iter: 5\n",
      "iteration: 4 of max_iter: 5\n",
      "iteration: 5 of max_iter: 5\n",
      "done in 169.602s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: con torax nodul derech no densid aument imag estudi radiografi probabl pulmon lateral posteroanterior proyeccion lsd izquierd pacient cit valor\n",
      "Topic #1: apreci dorsal escoliosis cambi column marc torax degener cifosis bronquiectasi relevancia mecan cuerp libres convex vertebral acun dorsolumbar suci espondilosis\n",
      "Topic #2: basal anterior izquierd control relevantes tac cambi marcapas aort derech con secundari proyect toracico elong bicameral elongada crecimient quirurg derecho\n",
      "Topic #3: estudi previ con respect cambi fech hili relev prominent comp orig radiolog identif compar vascular pleural mejori relacion derram objetiv\n",
      "Topic #4: normal dentr indic cardiotorac limit normalidad proces atelectasi alto esternotomi aument subsegmentari infecci lamin clinic neumoni valor medi media lid\n",
      "Topic #5: alter sin elongacion parenquim aortic aortica significativos significativas pulmonar cardiomegalia ateromatosis herni tronc lev aort hiato supraaorticos rest hiat supraaort\n",
      "Topic #6: costal fractur atrap cardiomegali derecha sign hallazgos aere call arco derech cerclaj izquierd aereo arcos posterior ose protesis parrill humeral\n",
      "Topic #7: sign epoc radiolog no pulmon enfermed dorsolumb metastas evident sugest mamari objetiv curv ict sug derechas insuficient izquierda fall ic\n",
      "Topic #8: con extrem derech distal central superior sond via nasogastr catet cav tub yugul discret subclavi mediastin endotraqueal izquierd trav venos\n",
      "Topic #9: atelectasi infiltr condensacion lobul pequen izquierd preoperatori imagen izquierda derech opac superior bas inferior cambios rest lm retrocardiac neumotorax 01\n",
      "Topic #10: no pulmonar ni infiltr condens siluet grand alteraciones parenquimat observ cardiomediastin pulmonares entid cirugi plac inspir inter visualiz nodul rot\n",
      "Topic #11: cambi con bilateral edad patron cronic pulmon intersticial pacient pulmonar infiltr camp predomini acord bibasal relacion compat alveol difus bas\n",
      "Topic #12: pleural sen costofren derech con izquierd pinzamient engros derram izquierdo derecho hemitorax apical calcific hemidiafragm tract pleuroparenquimat liger granulom volum\n",
      "Topic #13: sin hallazg signific radiolog patolog significacion ven rest patologico reservori fdo portador aspect dra picaz previo resident relev inter relevantes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "df = pd.read_csv('report_sentences_preprocessed.csv', encoding=\"ISO-8859-1\", na_filter=False)\n",
    "data = pd.Series(df['v_preprocessed']).tolist()\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "\n",
    "\n",
    "n_features = 1000\n",
    "n_components = 14\n",
    "n_top_words = 20\n",
    "n_samples = len(data)\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "#words occurring in only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features)\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features)\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0,\n",
    "                                evaluate_every = 128,\n",
    "                                verbose = 1)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Topic extraction using doc2vec and k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec (also called Paragraph Vectors) is a generalization of Word2Vec, which learns vectors from documents (https://cs.stanford.edu/~quocle/paragraph_vector.pdf). Then the K-means algorithm is used to cluster those vectors in topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate doc2vec we use gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 1.786s.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "df = pd.read_csv('report_sentences_preprocessed.csv', encoding=\"ISO-8859-1\", na_filter=False)\n",
    "text = pd.Series(df['v_preprocessed']).str.cat(sep=' ')\n",
    "data = [x.strip() for x in text.split('.')  if x.strip() != '']\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_corpus(data):\n",
    "    for i, line in enumerate(data):\n",
    "        line = list(filter(None, line.split()))\n",
    "        yield gensim.models.doc2vec.TaggedDocument(line,[i])\n",
    "train_corpus = list(preprocess_corpus(data))   \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(size=300, window=10, min_count=5, workers=11,alpha=0.025, min_alpha=0.025, iter=55) # use fixed learning rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.build_vocab(list(train_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time model.train(list(train_corpus), total_examples=model.corpus_count, epochs=model.iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('gensim_doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec.load('gensim_doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15340352, -0.11914615,  0.01125181, -0.08972302, -0.06965642,\n",
       "       -0.06225431,  0.00456697,  0.13876516, -0.03326254, -0.04685351,\n",
       "        0.11211377,  0.12251745,  0.04491276, -0.06148997,  0.13704689,\n",
       "       -0.05602381,  0.02089587,  0.03450793,  0.10800999, -0.09400132,\n",
       "       -0.13894641, -0.16020191, -0.05783847,  0.07556529,  0.03521203,\n",
       "       -0.11349928,  0.01542531,  0.2096909 ,  0.04083255, -0.09696309,\n",
       "       -0.01472371, -0.0388328 ,  0.05001611, -0.07439538,  0.09838079,\n",
       "       -0.01198428, -0.01821596, -0.11436306, -0.14083408,  0.00779142,\n",
       "        0.0995015 ,  0.07938567,  0.03741743, -0.03562498,  0.23675995,\n",
       "        0.07780671, -0.12604718,  0.12318231,  0.03296375, -0.02621838], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(['sin', 'hallazg', 'signific'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sign', 'radiolog', 'epoc']\n",
      "156111\n",
      "['radiografi', 'torax', 'posteroanterior', 'lateral']\n",
      "39595\n",
      "['no', 'identif', 'sign', 'radiolog', 'derram', 'pleural', 'signific']\n",
      "107\n",
      "['sin', 'hallazg', 'signific']\n",
      "204014\n",
      "['cambi', 'engros', 'pleural', 'apical', 'bilateral', 'nodular', 'probabl', 'granulom', 'secundari', 'enfermed', 'residual', 'no', 'dispon', 'radiografi', 'previ', 'pod', 'compar']\n",
      "1\n",
      "['tub', 'endotraqueal', '1']\n",
      "192\n",
      "['granulom', 'calcific', 'vertic', 'derech', 'cardiomegali']\n",
      "29591\n",
      "['compar', 'con', 'estudi', 'previ', 'fech', '03', '01', '2001', 'objetiv', 'resolucion', 'parcial', 'infiltr', 'neumon', 'basal', 'derech', 'resolucion', 'practic', 'complet', 'basal', 'izquierd']\n",
      "24\n",
      "['sin', 'hallazg', 'significacion', 'patolog', 'cambi', 'secundari', 'cirugi', 'vertic', 'pulmon', 'derech']\n",
      "26\n",
      "['tub', 'endotraqueal', '2', '5', 'cm', 'carin']\n",
      "58074\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "#for doc_id in range(len(train_corpus)):\n",
    "for doc_id in range(10):\n",
    "    print(train_corpus[doc_id].words)\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    \n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    print(rank)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1,\n",
       "         24: 1,\n",
       "         26: 1,\n",
       "         107: 1,\n",
       "         192: 1,\n",
       "         29591: 1,\n",
       "         39595: 1,\n",
       "         58074: 1,\n",
       "         156111: 1,\n",
       "         204014: 1})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(ranks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (9): «tub endotraqueal 2 5 cm carin»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (267180, 0.9394081234931946): «via central subclavi izquierd termi»\n",
      "\n",
      "MEDIAN (157240, 0.5713056325912476): «mastectomi izquierd»\n",
      "\n",
      "LEAST (343335, -0.29552340507507324): «implantefis»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: try TURI https://github.com/apple/turicreate/blob/master/userguide/text/intro.md"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:aind]",
   "language": "python",
   "name": "conda-env-aind-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
